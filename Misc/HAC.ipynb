{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-17T15:01:49.763855Z",
     "start_time": "2025-08-17T14:58:48.970388Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Import necessary libraries for spatial analysis, clustering, and visualization\n",
    "import os, fiona, folium, shapely, geopandas as gpd, pandas as pd, numpy as np, osmnx as ox, matplotlib.pyplot as plt\n",
    "from libpysal.weights import DistanceBand\n",
    "from esda.moran import Moran_Local\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import DBSCAN\n",
    "from shapely.geometry import Polygon, MultiPoint, shape\n",
    "from scipy.spatial import Delaunay\n",
    "from scipy.stats import gaussian_kde\n",
    "from rasterio.features import shapes\n",
    "from affine import Affine"
   ],
   "id": "47b9f413c7dd6a92",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "1. Calling historical tax data",
   "id": "4c2a72128e1731bc"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-17T14:58:29.731334Z",
     "start_time": "2025-08-17T14:58:14.184304Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Read Mecklenburg County boundary shapefile and dissolve into a single geometry\n",
    "meck_bo = gpd.read_file(\"../../../Data/Original_dataset/Archive/mecklenburgcounty_boundary/MecklenburgCounty_Boundary.shp\")\n",
    "county_geom = meck_bo.unary_union  # dissolve to a single polygon\n",
    "\n",
    "\n",
    "year = 2010 # Define year\n",
    "\n",
    "dataset_path = f\"../../../Data/Histoical_tax_data/main_files/tax_{year}.shp\" # Path to geodatabase with historical tax data\n",
    "\n",
    "layers = fiona.listlayers(os.path.dirname(dataset_path)); print(layers) # List layers available in the geodatabase\n",
    "\n",
    "tax_file = gpd.read_file(dataset_path) # Load tax parcel data for the given year\n",
    "\n",
    "tax_file = tax_file[~tax_file.geometry.is_empty & tax_file.geometry.notnull()] # Drop records with empty or null geometries for data integrity\n",
    "\n",
    "# Extarcting a sample of the dataset (the file is large)\n",
    "xmin, ymin, xmax, ymax = tax_file.total_bounds # Get bounding box manually or from a polygon\n",
    "xmax_sample = xmin + 0.4 * (xmax - xmin); ymax_sample = ymin + 0.4 * (ymax - ymin) #take a box covering 20% of the width & height, starting from xmin, ymin\n",
    "sample_box = gpd.GeoSeries([shapely.geometry.box(xmin, ymin, xmax_sample, ymax_sample)], crs=tax_file.crs)\n",
    "tax_file = tax_file[tax_file.geometry.within(sample_box.iloc[0])] # Filter points in this box\n",
    "\n",
    "tax_file"
   ],
   "id": "3cd29e37fa4a9f5c",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\erfan\\AppData\\Local\\Temp\\ipykernel_30168\\2465567144.py:3: DeprecationWarning: The 'unary_union' attribute is deprecated, use the 'union_all()' method instead.\n",
      "  county_geom = meck_bo.unary_union  # dissolve to a single polygon\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[2], line 10\u001B[0m\n\u001B[0;32m      6\u001B[0m year \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m2010\u001B[39m \u001B[38;5;66;03m# Define year\u001B[39;00m\n\u001B[0;32m      8\u001B[0m dataset_path \u001B[38;5;241m=\u001B[39m \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m../../../Data/Histoical_tax_data/main_files/tax_\u001B[39m\u001B[38;5;132;01m{\u001B[39;00myear\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m.shp\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;66;03m# Path to geodatabase with historical tax data\u001B[39;00m\n\u001B[1;32m---> 10\u001B[0m layers \u001B[38;5;241m=\u001B[39m fiona\u001B[38;5;241m.\u001B[39mlistlayers(os\u001B[38;5;241m.\u001B[39mpath\u001B[38;5;241m.\u001B[39mdirname(dataset_path)); \u001B[38;5;28mprint\u001B[39m(layers) \u001B[38;5;66;03m# List layers available in the geodatabase\u001B[39;00m\n\u001B[0;32m     12\u001B[0m tax_file \u001B[38;5;241m=\u001B[39m gpd\u001B[38;5;241m.\u001B[39mread_file(dataset_path) \u001B[38;5;66;03m# Load tax parcel data for the given year\u001B[39;00m\n\u001B[0;32m     14\u001B[0m tax_file \u001B[38;5;241m=\u001B[39m tax_file[\u001B[38;5;241m~\u001B[39mtax_file\u001B[38;5;241m.\u001B[39mgeometry\u001B[38;5;241m.\u001B[39mis_empty \u001B[38;5;241m&\u001B[39m tax_file\u001B[38;5;241m.\u001B[39mgeometry\u001B[38;5;241m.\u001B[39mnotnull()] \u001B[38;5;66;03m# Drop records with empty or null geometries for data integrity\u001B[39;00m\n",
      "Cell \u001B[1;32mIn[2], line 10\u001B[0m\n\u001B[0;32m      6\u001B[0m year \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m2010\u001B[39m \u001B[38;5;66;03m# Define year\u001B[39;00m\n\u001B[0;32m      8\u001B[0m dataset_path \u001B[38;5;241m=\u001B[39m \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m../../../Data/Histoical_tax_data/main_files/tax_\u001B[39m\u001B[38;5;132;01m{\u001B[39;00myear\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m.shp\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;66;03m# Path to geodatabase with historical tax data\u001B[39;00m\n\u001B[1;32m---> 10\u001B[0m layers \u001B[38;5;241m=\u001B[39m fiona\u001B[38;5;241m.\u001B[39mlistlayers(os\u001B[38;5;241m.\u001B[39mpath\u001B[38;5;241m.\u001B[39mdirname(dataset_path)); \u001B[38;5;28mprint\u001B[39m(layers) \u001B[38;5;66;03m# List layers available in the geodatabase\u001B[39;00m\n\u001B[0;32m     12\u001B[0m tax_file \u001B[38;5;241m=\u001B[39m gpd\u001B[38;5;241m.\u001B[39mread_file(dataset_path) \u001B[38;5;66;03m# Load tax parcel data for the given year\u001B[39;00m\n\u001B[0;32m     14\u001B[0m tax_file \u001B[38;5;241m=\u001B[39m tax_file[\u001B[38;5;241m~\u001B[39mtax_file\u001B[38;5;241m.\u001B[39mgeometry\u001B[38;5;241m.\u001B[39mis_empty \u001B[38;5;241m&\u001B[39m tax_file\u001B[38;5;241m.\u001B[39mgeometry\u001B[38;5;241m.\u001B[39mnotnull()] \u001B[38;5;66;03m# Drop records with empty or null geometries for data integrity\u001B[39;00m\n",
      "File \u001B[1;32m_pydevd_bundle/pydevd_cython_win32_311_64.pyx:1186\u001B[0m, in \u001B[0;36m_pydevd_bundle.pydevd_cython_win32_311_64.SafeCallWrapper.__call__\u001B[1;34m()\u001B[0m\n",
      "File \u001B[1;32m_pydevd_bundle/pydevd_cython_win32_311_64.pyx:627\u001B[0m, in \u001B[0;36m_pydevd_bundle.pydevd_cython_win32_311_64.PyDBFrame.trace_dispatch\u001B[1;34m()\u001B[0m\n",
      "File \u001B[1;32m_pydevd_bundle/pydevd_cython_win32_311_64.pyx:1103\u001B[0m, in \u001B[0;36m_pydevd_bundle.pydevd_cython_win32_311_64.PyDBFrame.trace_dispatch\u001B[1;34m()\u001B[0m\n",
      "File \u001B[1;32m_pydevd_bundle/pydevd_cython_win32_311_64.pyx:1065\u001B[0m, in \u001B[0;36m_pydevd_bundle.pydevd_cython_win32_311_64.PyDBFrame.trace_dispatch\u001B[1;34m()\u001B[0m\n",
      "File \u001B[1;32m_pydevd_bundle/pydevd_cython_win32_311_64.pyx:585\u001B[0m, in \u001B[0;36m_pydevd_bundle.pydevd_cython_win32_311_64.PyDBFrame.do_wait_suspend\u001B[1;34m()\u001B[0m\n",
      "File \u001B[1;32mC:\\Program Files\\JetBrains\\DataSpell 2025.2\\plugins\\python-ce\\helpers\\pydev\\pydevd.py:1196\u001B[0m, in \u001B[0;36mPyDB.do_wait_suspend\u001B[1;34m(self, thread, frame, event, arg, send_suspend_message, is_unhandled_exception)\u001B[0m\n\u001B[0;32m   1193\u001B[0m         from_this_thread\u001B[38;5;241m.\u001B[39mappend(frame_id)\n\u001B[0;32m   1195\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_threads_suspended_single_notification\u001B[38;5;241m.\u001B[39mnotify_thread_suspended(thread_id, stop_reason):\n\u001B[1;32m-> 1196\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_do_wait_suspend\u001B[49m\u001B[43m(\u001B[49m\u001B[43mthread\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mframe\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mevent\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43marg\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msuspend_type\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfrom_this_thread\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mC:\\Program Files\\JetBrains\\DataSpell 2025.2\\plugins\\python-ce\\helpers\\pydev\\pydevd.py:1211\u001B[0m, in \u001B[0;36mPyDB._do_wait_suspend\u001B[1;34m(self, thread, frame, event, arg, suspend_type, from_this_thread)\u001B[0m\n\u001B[0;32m   1208\u001B[0m             \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_call_mpl_hook()\n\u001B[0;32m   1210\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mprocess_internal_commands()\n\u001B[1;32m-> 1211\u001B[0m         \u001B[43mtime\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msleep\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m0.01\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1213\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcancel_async_evaluation(get_current_thread_id(thread), \u001B[38;5;28mstr\u001B[39m(\u001B[38;5;28mid\u001B[39m(frame)))\n\u001B[0;32m   1215\u001B[0m \u001B[38;5;66;03m# process any stepping instructions\u001B[39;00m\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "2. Data filtering and meta configurations",
   "id": "9210990b633a6e1b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "#2. Meta configurations\n",
    "\n",
    "county_wgs = meck_bo.to_crs(epsg=4326)\n",
    "\n",
    "tax_file.columns = tax_file.columns.str.lower() #Make column names lowercase\n",
    "\n",
    "tax_file['lv_acre'] = tax_file['landvalue'] / tax_file.geometry.area / 43560 #Calculate landvalue column\n",
    "\n",
    "residential_types = [  # List of residential building types to exclude from analysis (optional)\n",
    "    'RES', 'TOWNHOUSE', 'DUP-TRIPLEX', 'CONDO', 'COMM CONDO', 'CONDO-HI', 'MFD HOME-DW',\n",
    "    'APT-GDN', 'APT-TOWNHSE', 'APT-HIRISE', 'MFD HOME-SW', 'PATIO HOME', 'GROUP HOME'\n",
    "]\n",
    "\n",
    "tax_file = tax_file[ # Filter out residential parcels and any records with blank or null building descriptions\n",
    "    (~tax_file['descbuildi'].isin(residential_types)) &  # exclude residential types\n",
    "    (tax_file['descbuildi'].str.strip() != '') &          # exclude empty strings\n",
    "    (tax_file['descbuildi'].notnull())                     # exclude null values\n",
    "]\n",
    "\n",
    "tax_file['centroid'] = tax_file.geometry.centroid # Create a new 'centroid' column with Point geometries\n",
    "\n",
    "tax_file['x'] = tax_file.geometry.centroid.x; tax_file['y'] = tax_file.geometry.centroid.y # Add separate columns for centroid x and y coordinates\n",
    "\n",
    "coords = tax_file[['x', 'y']].values # Extract XY coordinates from the geometries for clustering\n",
    "\n",
    "elevation_values = tax_file[\"lv_acre\"].values # Extract land value per acre attribute (used as a weight/feature)\n",
    "\n",
    "w = DistanceBand.from_dataframe(tax_file, threshold=500, binary=False, alpha=-1, silence_warnings=True) # Create spatial weights matrix with inverse distance weighting within 500 meters threshold\n",
    "w.transform = 'r'  # row-standardize weights\n",
    "\n",
    "#Visualization of the final dataset\n",
    "fig, ax = plt.subplots(1, 1, figsize=(20, 20)); tax_file.plot(ax=ax, color='blue', edgecolor='black', markersize=8, alpha=0.7)\n",
    "ax.set_title('Case Study Area', fontweight='bold', size=20); ax.set_xlabel('Longitude'); ax.set_ylabel('Latitude'); plt.show()"
   ],
   "id": "62efba618a647872",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "3. Performing HAC using Spatial DBSCAN",
   "id": "e6fa0f6e46491da2"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-12T02:14:04.355575Z",
     "start_time": "2025-08-12T02:14:00.102800Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#DBSCAN config\n",
    "eps = 0.5\n",
    "min_samples = 5\n",
    "\n",
    "#Running DBSCAN\n",
    "features = tax_file[['x', 'y', 'lv_acre']].values\n",
    "scaled_features = StandardScaler().fit_transform(features)\n",
    "db = DBSCAN(eps = eps, min_samples = min_samples).fit(scaled_features)\n",
    "tax_file['cluster'] = db.labels_\n",
    "\n",
    "tax_file['value_group'] = pd.qcut( #QUANTILE GROUPING\n",
    "    tax_file['lv_acre'], \n",
    "    q=10, \n",
    "    labels=False, \n",
    "    duplicates='drop'\n",
    ")\n",
    "\n",
    "agg_tax_file = tax_file.dissolve(by='value_group', as_index=False) # Aggregate parcels by value group\n",
    "\n",
    "\n",
    "#Visualization\n",
    "\n",
    "agg_tax_file = agg_tax_file[['value_group', 'geometry']] # Keep only necessary columns and convert any datetime to string\n",
    "for col in agg_tax_file.columns:\n",
    "    if pd.api.types.is_datetime64_any_dtype(agg_tax_file[col]):\n",
    "        agg_tax_file[col] = agg_tax_file[col].astype(str)\n",
    "\n",
    "agg_tax_wgs = agg_tax_file.to_crs(epsg=4326) # Reproject to WGS84 for Folium\n",
    "\n",
    "max_val_group = agg_tax_wgs[agg_tax_wgs['value_group'] == agg_tax_wgs['value_group'].max()] # Calculate max value_group for colormap scaling\n",
    "\n",
    "center = agg_tax_wgs.geometry.centroid.unary_union.centroid # Calculate center of map using centroid of all parcels\n",
    "\n",
    "m = folium.Map(location=[center.y, center.x], zoom_start=11, tiles='cartodbpositron')\n",
    "\n",
    "folium.GeoJson( # Add county boundary to map\n",
    "    county_wgs,\n",
    "    name=\"County Boundary\",\n",
    "    style_function=lambda x: {\"fillColor\": \"#00000000\", \"color\": \"black\", \"weight\": 2},\n",
    ").add_to(m)\n",
    "\n",
    "folium.GeoJson( # Add GeoJson layer with style and tooltip\n",
    "    max_val_group,\n",
    "        style_function=lambda feature: {\n",
    "        \"color\": \"red\",\n",
    "        \"weight\": 0.1,\n",
    "        \"fillOpacity\": 0.5},\n",
    ").add_to(m)\n",
    "\n",
    "m.save(f\"../../../output/map/HAC/DBSCAN_last_decile_{year}.html\") # Save to HTML file"
   ],
   "id": "97c8e260bc8c0b84",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ekefayat\\AppData\\Roaming\\Python\\Python310\\site-packages\\geopandas\\geodataframe.py:1819: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  super().__setitem__(key, value)\n",
      "C:\\Users\\ekefayat\\AppData\\Roaming\\Python\\Python310\\site-packages\\geopandas\\geodataframe.py:1819: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  super().__setitem__(key, value)\n",
      "C:\\Users\\ekefayat\\AppData\\Local\\Temp\\1\\ipykernel_3344\\3029958762.py:32: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  center = agg_tax_wgs.geometry.centroid.unary_union.centroid # Calculate center of map using centroid of all parcels\n",
      "C:\\Users\\ekefayat\\AppData\\Local\\Temp\\1\\ipykernel_3344\\3029958762.py:32: DeprecationWarning: The 'unary_union' attribute is deprecated, use the 'union_all()' method instead.\n",
      "  center = agg_tax_wgs.geometry.centroid.unary_union.centroid # Calculate center of map using centroid of all parcels\n"
     ]
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "4. Performing HAC using LISA",
   "id": "c1b7c18931bf6374"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-12T02:21:24.473205Z",
     "start_time": "2025-08-12T02:21:22.558308Z"
    }
   },
   "cell_type": "code",
   "source": [
    "y = tax_file['lv_acre'] # Extract dependent variable\n",
    "\n",
    "lisa = Moran_Local(y, w) # Compute Local Moran's I\n",
    "\n",
    "tax_file['Isig'] = lisa.p_sim < 0.05;  tax_file['Ilocal'] = lisa.Is # Add results to GeoDataFrame\n",
    "\n",
    "sig = lisa.p_sim < 0.05;  quad = lisa.q # Classification\n",
    "\n",
    "tax_file['cluster'] = 'Non-significant'\n",
    "tax_file.loc[sig & (quad == 1), 'cluster'] = 'High-High'\n",
    "tax_file.loc[sig & (quad == 2), 'cluster'] = 'Low-High'\n",
    "tax_file.loc[sig & (quad == 3), 'cluster'] = 'Low-Low'\n",
    "tax_file.loc[sig & (quad == 4), 'cluster'] = 'High-Low'\n",
    "\n",
    "\n",
    "#Visualization\n",
    "\n",
    "tax_file_wgs = tax_file.to_crs(epsg=4326)\n",
    "\n",
    "high_high_group = tax_file_wgs[tax_file_wgs['cluster'] == 'High-High']; high_high_group = high_high_group[[\"cluster\", \"geometry\"]] # Filtering high_high_value_group\n",
    "\n",
    "for col in high_high_group.columns: #convert any datetime to string\n",
    "    if pd.api.types.is_datetime64_any_dtype(high_high_group[col]):\n",
    "        high_high_group[col] = high_high_group[col].astype(str)\n",
    "\n",
    "center = tax_file_wgs.geometry.centroid.unary_union.centroid # Map center\n",
    "\n",
    "m = folium.Map(location=[center.y, center.x], zoom_start=11, tiles=\"cartodbpositron\") # Create Folium map\n",
    "\n",
    "folium.GeoJson( # Add county boundary to map\n",
    "    county_wgs,\n",
    "    name=\"County Boundary\",\n",
    "    style_function=lambda x: {\"fillColor\": \"#00000000\", \"color\": \"black\", \"weight\": 2},\n",
    ").add_to(m)\n",
    "\n",
    "folium.GeoJson( # Add polygons to map\n",
    "    high_high_group,\n",
    "        style_function=lambda feature: {\n",
    "        \"color\": \"red\",\n",
    "        \"weight\": 0.1,\n",
    "        \"fillOpacity\": 0.5}\n",
    ").add_to(m)\n",
    "\n",
    "m.save(f\"../../../output/map/HAC/lisa_high_high_{year}.html\") # Save map"
   ],
   "id": "abbd8408d61a2805",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ekefayat\\AppData\\Roaming\\Python\\Python310\\site-packages\\esda\\moran.py:1059: RuntimeWarning: invalid value encountered in divide\n",
      "  self.z_sim = (self.Is - self.EI_sim) / self.seI_sim\n",
      "C:\\Users\\ekefayat\\AppData\\Roaming\\Python\\Python310\\site-packages\\geopandas\\geodataframe.py:1819: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  super().__setitem__(key, value)\n",
      "C:\\Users\\ekefayat\\AppData\\Local\\Temp\\1\\ipykernel_3344\\1315615462.py:26: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  center = tax_file_wgs.geometry.centroid.unary_union.centroid # Map center\n",
      "C:\\Users\\ekefayat\\AppData\\Local\\Temp\\1\\ipykernel_3344\\1315615462.py:26: DeprecationWarning: The 'unary_union' attribute is deprecated, use the 'union_all()' method instead.\n",
      "  center = tax_file_wgs.geometry.centroid.unary_union.centroid # Map center\n"
     ]
    }
   ],
   "execution_count": 27
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "5. Performing HAC using Natual Cities Approach",
   "id": "1448f694bb3aa500"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-12T02:39:09.902068Z",
     "start_time": "2025-08-12T02:39:03.620163Z"
    }
   },
   "cell_type": "code",
   "source": [
    "tri = Delaunay(coords) # Compute Delaunay triangulation from parcel coordinates\n",
    "\n",
    "triangles = coords[tri.simplices] # Extract triangle vertices coordinates\n",
    "\n",
    "triangle_polygons = []; kept_triangle_indices = [];  filtered_triangle_values = [] # Initialize lists to store valid triangle polygons and their average values\n",
    "\n",
    "\n",
    "# Iterate over each triangle simplex\n",
    "for i, simplex in enumerate(tri.simplices):\n",
    "    pts = coords[simplex]\n",
    "    poly = Polygon(pts)  # create polygon from triangle vertices\n",
    "\n",
    "    # Keep polygons valid and located within county boundary\n",
    "    if poly.is_valid and poly.centroid.within(county_geom):\n",
    "        triangle_polygons.append(poly)\n",
    "        kept_triangle_indices.append(i)\n",
    "\n",
    "        # Calculate average land value for triangle vertices\n",
    "        avg_val = np.mean(elevation_values[simplex])\n",
    "        filtered_triangle_values.append(avg_val)\n",
    "\n",
    "filtered_triangle_values = np.array(filtered_triangle_values) # Convert filtered values to numpy array\n",
    "\n",
    "selected_mask = filtered_triangle_values > filtered_triangle_values.mean() # Select triangles with average land value above the mean\n",
    "\n",
    "# Create GeoDataFrame of selected polygons (natural cities)\n",
    "natural_city_polys = [triangle_polygons[i] for i, keep in enumerate(selected_mask) if keep]\n",
    "natural_cities_gdf = gpd.GeoDataFrame(geometry=natural_city_polys, crs=tax_file.crs)\n",
    "\n",
    "# Prepare data for web visualization by converting to WGS84 projection\n",
    "natural_cities_wgs = natural_cities_gdf.to_crs(epsg=4326)\n",
    "\n",
    "center = county_wgs.geometry.centroid # Get centroid of county for map center\n",
    "\n",
    "m = folium.Map(location=[center.y, center.x], zoom_start=11, tiles=\"cartodbpositron\") # Create Folium map centered on county centroid\n",
    "\n",
    "# Add county boundary to map (transparent fill, black border)\n",
    "folium.GeoJson(\n",
    "    county_wgs,\n",
    "    name=\"County Boundary\",\n",
    "    style_function=lambda x: {\"fillColor\": \"#00000000\", \"color\": \"black\", \"weight\": 2},\n",
    ").add_to(m)\n",
    "\n",
    "# Add natural cities polygons with red fill to map\n",
    "folium.GeoJson(\n",
    "    natural_cities_wgs,\n",
    "        style_function=lambda feature: {\n",
    "        \"color\": \"red\",\n",
    "        \"weight\": 0.1,\n",
    "        \"fillOpacity\": 0.5}\n",
    ").add_to(m)\n",
    "\n",
    "# Save the map as HTML file\n",
    "m.save(f\"../../../output/map/HAC/natural_cities_map_{year}.html\")"
   ],
   "id": "1c5fbcd0c38ed9f2",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ekefayat\\AppData\\Local\\Temp\\1\\ipykernel_3344\\2978754773.py:33: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  center = county_wgs.geometry.centroid # Get centroid of county for map center\n",
      "C:\\Users\\ekefayat\\AppData\\Roaming\\Python\\Python310\\site-packages\\folium\\utilities.py:94: FutureWarning: Calling float on a single element Series is deprecated and will raise a TypeError in the future. Use float(ser.iloc[0]) instead\n",
      "  float(coord)\n",
      "C:\\Users\\ekefayat\\AppData\\Roaming\\Python\\Python310\\site-packages\\folium\\utilities.py:100: FutureWarning: Calling float on a single element Series is deprecated and will raise a TypeError in the future. Use float(ser.iloc[0]) instead\n",
      "  if math.isnan(float(coord)):\n",
      "C:\\Users\\ekefayat\\AppData\\Roaming\\Python\\Python310\\site-packages\\folium\\utilities.py:102: FutureWarning: Calling float on a single element Series is deprecated and will raise a TypeError in the future. Use float(ser.iloc[0]) instead\n",
      "  return [float(x) for x in coords]\n"
     ]
    }
   ],
   "execution_count": 28
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "6. Performing HAC using natural cities apporach for street node",
   "id": "6ece9c092c5c2deb"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Download street network graph for Mecklenburg County\n",
    "place_name = \"Mecklenburg County, North Carolina, USA\"\n",
    "G = ox.graph_from_place(place_name, network_type='drive')\n",
    "\n",
    "# Extract nodes from the graph as GeoDataFrame\n",
    "nodes = ox.graph_to_gdfs(G, edges=False)\n",
    "\n",
    "# Project nodes to metric coordinate system (EPSG:3857) for clustering\n",
    "nodes_proj = nodes.to_crs(epsg=3857)\n",
    "\n",
    "# Extract coordinates of nodes as array for clustering\n",
    "coords_nodes = np.column_stack((nodes_proj.geometry.x, nodes_proj.geometry.y))\n",
    "\n",
    "# Apply DBSCAN clustering on nodes with 400 meters epsilon, min_samples=1\n",
    "db = DBSCAN(eps=400, min_samples=5).fit(coords_nodes)\n",
    "\n",
    "# Assign cluster labels to nodes\n",
    "nodes_proj['cluster'] = db.labels_\n",
    "\n",
    "# Generate convex hull polygons for clusters with more than 3 nodes\n",
    "clusters = []\n",
    "for cluster_id in nodes_proj['cluster'].unique():\n",
    "    group = nodes_proj[nodes_proj['cluster'] == cluster_id]\n",
    "    if len(group) > 3:\n",
    "        polygon = MultiPoint(group.geometry.tolist()).convex_hull\n",
    "        clusters.append({'cluster': cluster_id, 'geometry': polygon})\n",
    "\n",
    "# Create GeoDataFrame of clusters representing natural cities\n",
    "natural_cities = gpd.GeoDataFrame(clusters, crs=nodes_proj.crs)\n",
    "\n",
    "# Reproject to WGS84 for web visualization with Folium\n",
    "natural_cities_latlon = natural_cities.to_crs(epsg=4326)\n",
    "\n",
    "# Center map on average centroid of clusters\n",
    "center = [natural_cities_latlon.geometry.centroid.y.mean(), natural_cities_latlon.geometry.centroid.x.mean()]\n",
    "\n",
    "# Create Folium map centered on clusters\n",
    "m = folium.Map(location=center, zoom_start=11, tiles='cartodbpositron')\n",
    "\n",
    "# Add county boundary to map (transparent fill, black border)\n",
    "folium.GeoJson(\n",
    "    county_wgs,\n",
    "    name=\"County Boundary\",\n",
    "    style_function=lambda x: {\"fillColor\": \"#00000000\", \"color\": \"black\", \"weight\": 2},\n",
    ").add_to(m)\n",
    "\n",
    "# Add each cluster polygon to the map with blue fill\n",
    "for _, row in natural_cities_latlon.iterrows():\n",
    "    sim_geo = folium.GeoJson(\n",
    "        row['geometry'], \n",
    "        style_function=lambda x: {\n",
    "            'fillColor': 'blue',\n",
    "            'color': 'black',\n",
    "            'weight': 0.1,\n",
    "            'fillOpacity': 0.5\n",
    "        }\n",
    "    )\n",
    "    sim_geo.add_to(m)\n",
    "\n",
    "# Save the map to an HTML file\n",
    "m.save(f\"../../../output/map/HAC/natural_cities_map_street_nodes.html\")"
   ],
   "id": "1fdd8e118a90fcf1"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "7. Performing HAC using Kernel Density",
   "id": "85f7296708496e52"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-12T02:51:56.078712Z",
     "start_time": "2025-08-12T02:51:36.928972Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#KDE config\n",
    "bw_method = 0.5\n",
    "\n",
    "xmin, ymin, xmax, ymax = tax_file.total_bounds # Extract bounding box of tax parcels to define KDE grid extent\n",
    "\n",
    "xres = yres = 200 # Define resolution of KDE grid (number of cells in x and y direction)\n",
    "\n",
    "xgrid = np.linspace(xmin, xmax, xres); ygrid = np.linspace(ymin, ymax, yres) # Create equally spaced grid points in x and y dimensions\n",
    "\n",
    "xv, yv = np.meshgrid(xgrid, ygrid) # Create 2D meshgrid of coordinates\n",
    "\n",
    "grid_coords = np.vstack([xv.ravel(), yv.ravel()]) # Stack grid coordinates into shape (2, N) for KDE evaluation\n",
    "\n",
    "kde = gaussian_kde(coords.T, weights=elevation_values, bw_method=bw_method) # Compute weighted KDE using parcel coordinates and land value as weights\n",
    "\n",
    "z = kde(grid_coords).reshape((yres, xres))  # Evaluate KDE values on grid points and reshape to 2D grid\n",
    "\n",
    "threshold = np.percentile(z, 90); mask = z >= threshold # Threshold KDE to top 10% (90th percentile) to highlight dense clusters\n",
    "\n",
    "xcell = (xmax - xmin) / xres; ycell = (ymax - ymin) / yres # Calculate cell size in x and y directions\n",
    "\n",
    "transform = Affine.translation(xmin, ymin) * Affine.scale(xcell, ycell) # Create affine transform mapping grid cells to spatial coordinates\n",
    "\n",
    "shapes_gen = shapes(mask.astype(np.uint8), transform=transform) # Extract polygons representing contiguous clusters above threshold from raster mask\n",
    "\n",
    "polygons = [shape(geom) for geom, val in shapes_gen if val == 1] # Convert extracted shapes to shapely polygons\n",
    "\n",
    "\n",
    "kde_decile_gdf = gpd.GeoDataFrame(geometry=polygons, crs=tax_file.crs).dissolve() # Build GeoDataFrame from polygons and dissolve to merge contiguous polygons\n",
    "\n",
    "\n",
    "\n",
    "# Visualization\n",
    "\n",
    "kde_decile_wgs = kde_decile_gdf.to_crs(epsg=4326)\n",
    "\n",
    "center = kde_decile_wgs.geometry.centroid.iloc[0] # Get centroid of cluster polygons for map center\n",
    "\n",
    "m = folium.Map(location=[center.y, center.x], zoom_start=11, tiles=\"cartodbpositron\") # Create Folium map centered on KDE clusters\n",
    "\n",
    "folium.GeoJson( # Add KDE top decile polygons with purple fill to the map\n",
    "    kde_decile_gdf,\n",
    "        style_function=lambda feature: {\n",
    "        \"color\": \"red\",\n",
    "        \"weight\": 0.1,\n",
    "        \"fillOpacity\": 0.5}\n",
    ").add_to(m)\n",
    "\n",
    "m.save(f\"../../../output/map/HAC/kde_nonres_last_decile_{year}.html\") # Save map as HTML file"
   ],
   "id": "69635e845a0a52e2",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ekefayat\\AppData\\Local\\Temp\\1\\ipykernel_3344\\401756848.py:37: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  center = kde_decile_wgs.geometry.centroid.iloc[0] # Get centroid of cluster polygons for map center\n"
     ]
    }
   ],
   "execution_count": 38
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "32c7e1f14c2a5084"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
